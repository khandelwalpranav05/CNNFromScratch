{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution(image,filt,bias,s=1):\n",
    "    \n",
    "    (n_f,n_c_f,f,_) = filt.shape\n",
    "    n_c,in_dim,_ = image.shape\n",
    "    \n",
    "    out_dim = int((in_dim - f)/s) + 1\n",
    "    \n",
    "    assert n_c==n_c_f\n",
    "    \n",
    "    out = np.zeros((n_f,out_dim,out_dim))\n",
    "    \n",
    "    for curr_f in range(n_f):\n",
    "        curr_y = out_y = 0\n",
    "        \n",
    "        while curr_y + f <= in_dim:\n",
    "            curr_x = out_x = 0\n",
    "            \n",
    "            while curr_x + f<=in_dim:\n",
    "                out[curr_f,out_y,out_x] = np.sum(filt[curr_f] * image[:,curr_y:curr_y + f,curr_x:curr_x + f]) + bias[curr_f]\n",
    "                curr_x +=s\n",
    "                out_x += 1\n",
    "            \n",
    "            curr_y +=s\n",
    "            out_y +=1\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pooling(image,f=2,s=2):\n",
    "    \n",
    "    n_c,h_prev,w_prev = image.shape\n",
    "    \n",
    "    h = int((h_prev-f)/s) + 1\n",
    "    w = int((w_prev - f)/s) + 1\n",
    "    \n",
    "    downsampled = np.zeros((n_c,h,w))\n",
    "    \n",
    "    for i in range(n_c):\n",
    "        curr_y = out_y = 0\n",
    "        \n",
    "        while curr_y + g <=h_prev:\n",
    "            curr_x = out_x = 0\n",
    "            \n",
    "            while curr_x + f <=w_prev:\n",
    "                \n",
    "                downsampled[i,out_y,out_x] = np.max(image[i,curr_y:curr_y+f,curr_x:curr_x + f])\n",
    "                curr_x +=s\n",
    "                out_x +=1\n",
    "                \n",
    "            curr_y +=s\n",
    "            out_y +=1\n",
    "            \n",
    "    \n",
    "    return downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(raw_pred):\n",
    "    out = np.exp(raw_pred)\n",
    "    return out/np.sum(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lossFunction(prob,label):\n",
    "    return -np.sum(label*np.log(prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(filename,num_images,IMAGE_WIDTH):\n",
    "    print('Extracting',filename)\n",
    "    \n",
    "    with gzip.open(filename) as bytestream:\n",
    "        bytestream.read(16)\n",
    "        buf = bytestream.read(IMAGE_WIDTH*IMAGE_WIDTH*num_images)\n",
    "        data = np.frombuffer(buf,dtype=np.uint8).astype(np.float32)\n",
    "        data = data.reshape(num_images,IMAGE_WIDTH*IMAGE_WIDTH)\n",
    "        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_label(filename,num_images):\n",
    "    print('Extracting',filename)\n",
    "    \n",
    "    with gzip.open(filename) as bytestream:\n",
    "        bytestream.read(8)\n",
    "        buf = bytestream.read(1*num_images)\n",
    "        labels = np.frombuffer(buf,dtype=np.uint8).astype(np.int64)\n",
    "        \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterInitializer(size,scale = 1.0):\n",
    "    \n",
    "    stddev = scale/np.sqrt(np.prod(size))\n",
    "    return np.random.normal(scale=stddev,size=size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weightInitializer(size):\n",
    "    return np.random.standard_normal(size=size)*0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutionBackward(dconv_prev, conv_in, filt, s):\n",
    "    '''\n",
    "    Backpropagation through a convolutional layer. \n",
    "    '''\n",
    "    (n_f, n_c, f, _) = filt.shape\n",
    "    (_, orig_dim, _) = conv_in.shape\n",
    "    \n",
    "    dout = np.zeros(conv_in.shape) \n",
    "    dfilt = np.zeros(filt.shape)\n",
    "    dbias = np.zeros((n_f,1))\n",
    "    for curr_f in range(n_f):\n",
    "        \n",
    "        curr_y = out_y = 0\n",
    "        while curr_y + f <= orig_dim:\n",
    "            curr_x = out_x = 0\n",
    "            while curr_x + f <= orig_dim:\n",
    "               \n",
    "                dfilt[curr_f] += dconv_prev[curr_f, out_y, out_x] * conv_in[:, curr_y:curr_y+f, curr_x:curr_x+f]\n",
    "                \n",
    "                dout[:, curr_y:curr_y+f, curr_x:curr_x+f] += dconv_prev[curr_f, out_y, out_x] * filt[curr_f] \n",
    "                curr_x += s\n",
    "                out_x += 1\n",
    "            curr_y += s\n",
    "            out_y += 1\n",
    "        \n",
    "        dbias[curr_f] = np.sum(dconv_prev[curr_f])\n",
    "    \n",
    "    return dout, dfilt, dbias\n",
    "\n",
    "def nanargmax(arr):\n",
    "    '''\n",
    "    return index of the largest non-nan value in the array. Output is an ordered pair tuple\n",
    "    '''\n",
    "    idx = np.nanargmax(arr)\n",
    "    idxs = np.unravel_index(idx, arr.shape)\n",
    "    return idxs \n",
    "\n",
    "def maxpoolBackward(dpool, orig, f, s):\n",
    "    '''\n",
    "    Backpropagation through a maxpooling layer. The gradients are passed through the indices of greatest value in the original maxpooling during the forward step.\n",
    "    '''\n",
    "    (n_c, orig_dim, _) = orig.shape\n",
    "    \n",
    "    dout = np.zeros(orig.shape)\n",
    "    \n",
    "    for curr_c in range(n_c):\n",
    "        curr_y = out_y = 0\n",
    "        while curr_y + f <= orig_dim:\n",
    "            curr_x = out_x = 0\n",
    "            while curr_x + f <= orig_dim:\n",
    "                \n",
    "                (a, b) = nanargmax(orig[curr_c, curr_y:curr_y+f, curr_x:curr_x+f])\n",
    "                dout[curr_c, curr_y+a, curr_x+b] = dpool[curr_c, out_y, out_x]\n",
    "                \n",
    "                curr_x += s\n",
    "                out_x += 1\n",
    "            curr_y += s\n",
    "            out_y += 1\n",
    "        \n",
    "    return dout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conVet(image,label,params,conv_s,pool_f,pool_s):\n",
    "    \n",
    "    [f1,f2,w3,w4,b1,b2,b3,b4] = params\n",
    "    \n",
    "    conv1 = convolution(image,f1,b1,conv_s) #First convolutional operation\n",
    "    conv1[conv1<=0] = 0 #Introducing non linearity (RELU)\n",
    "    \n",
    "    conv2 = convolution(conv1,f2,b2,conv_s) #Second convolutional operation\n",
    "    conv2[conv2<=0] #Introducing non linearity (RELU)\n",
    "    \n",
    "    pooled = max_pooling(conv2,pool_f,pool_s) #max pooling the output of convolutional operation\n",
    "    \n",
    "    (n_f,dim_,_) = pooled.shape\n",
    "    fc = pooled.reshape((n_f*dim_*dim_,1)) #flatten\n",
    "    \n",
    "    z = w3.dot(fc) + b3\n",
    "    z[z<=0] = 0\n",
    "    \n",
    "    out = w4.dot(z) + b4\n",
    "    \n",
    "    \n",
    "    probs = softmax(out)\n",
    "    \n",
    "    loss = lossFunction(probs,label)\n",
    "    \n",
    "    #BackPropogation\n",
    "    \n",
    "    dout = probs - label\n",
    "    dw4 = dout.dot(z.T)\n",
    "    db4 = np.sum(dout,axis=1).reshape(b4.shape)\n",
    "    \n",
    "    dz = w4.T.dot(dout)\n",
    "    dz[z<=0] = 0\n",
    "    dw3 = dz.dot(fc.T)\n",
    "    db3 = np.sum(dz,axis= 1).reshape(b3.shape)\n",
    "    \n",
    "    dfc = w3.T.dot(dz)\n",
    "    dpool = dfc.reshape(pooled.shape)\n",
    "    \n",
    "    dconv2 = maxpoolBackward(dpool,conv2,pool_f,pool_s)\n",
    "    dconv2[conv2<=0] = 0\n",
    "    \n",
    "    dconv1, df2, db2 = convolutionBackward(dconv2, conv1, f2, conv_s)\n",
    "    dconv1[conv1<=0] = 0\n",
    "    \n",
    "    dimage,df1,db1 = convolutionBackward(dconv1,image,f1,conv_s)\n",
    "    \n",
    "    grades = [df1,df2,dw3,dw4,db1,db2,db3,db4]\n",
    "    \n",
    "    return grades,loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
